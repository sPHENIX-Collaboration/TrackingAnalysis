# Data macro for Physics Validation TF
This support starting from any level of DSTs, and produce various QA outputs

- Obtain DST lists
If you want to start from Raw Hit DSTs, please use ``getFiles_rawhit.sh``.
Modify here according to what run species (``run2pp`` or ``run3auau`` or ``run3pp``), run type (always ``physics``), ana build (``anaXXX``), cdb tag (always ``nocdbtag`` for raw hit DSTs), and version number (``vXXX``)
```
runspecies='run2pp'
runtype='physics'
anabuild='ana479'
cdbtag='nocdbtag'
version='v001'
```
Then change here according to how many events per DST (``NumEvtPerDst``) and how many events you want to analysis per job (``NumEvtPerJob``)
```
NumEvtPerDst=10000
NumEvtPerJob=10000
```
For example, you want to obtain raw hit DST list of run 53877, execute
```
./getFiles_rawhit.sh 53877
```
The output file list will show up in a new directory ``fileLists``.
If you want to analyze higher level of DSTs, e.g. cluster DST, seed DST, track DST, please use ``getFiles.sh``, and change the following lines:
```
runSpecies=run2pp
buildTag=ana506_2024p023_v001
dstType=DST_TRKR_TRACKS
nTotal=10000 #10000 events per segment
nEvents=5000 # nEvents per job
```
Execute in a similar way:
```
./getFiles.sh 53877
```

- Macro
Macro and run script are stored in ``macro/`` directory
```
Fun4All_HF.C  HF_selections.C  runHFreco.sh
```
Currently, it supports KFParticle QA for reconstructing four resonances: $K_S^0,\,\Lambda,\,\phi,\,D^0$ as well as various Tracking QA modules which depends on which level of DST you input.
For KFParticle QA, if you want to enable or disable specific channel, please go to ``HF_selections.C`` and modify here:
```
  bool run_pipi_reco = true;
  bool run_ppi_reco = true;
  bool run_KK_reco = true;
  bool run_Kpi_reco = true;
```
Currently, KFParticle nTuples will not be generated by default. Only QA histogram root files are generated. If you want to look into nTuples in detail, please enable this line:
```
  bool save_kfpntuple = true;
```
If you want get trigger info, detector info, and dEdx info,n your output nTuples please enable these lines:
```
bool get_trigger_info = true;
bool get_detector_info = true;
bool get_dEdx_info = true;
```
**These flags automatically input raw hit DSTs or cluster DSTs in Fun4All_HF.C**
If your input is high level DST (cluster,seed,track) which does not have GL1RAWHIT node, and you want to get trigger info, you need to enable ``get_trigger_info`` flag. Then, go to ``Fun4All_HF.C`` and change raw hit DST path to match with input DST
```c++
  if (get_trigger_info)
  {
    std::string gl1_file = "/sphenix/lustre01/sphnxpro/production/run2pp/physics/ana479_nocdbtag_v001/DST_STREAMING_EVENT_INTT0/run_"
                         + nice_rounded_down.str() + "_" + nice_rounded_up.str()
                         + "/dst/DST_STREAMING_EVENT_INTT0_run2pp_ana479_nocdbtag_v001-" + nice_runnumber.str() + "-" + nice_segment.str() + ".root";

    auto hitsintrig = new Fun4AllDstInputManager("TriggerInputManager");
    hitsintrig->fileopen(gl1_file);
    se->registerInputManager(hitsintrig);
  }
```
If your input is already raw hit DST, please disable ``get_trigger_info`` flag.
If your input is seed or track DST which do not contain cluster info, but you want to get detector info (cluster position etc.) and dEdx info, please enable 
```
bool get_detector_info = true;
bool get_dEdx_info = true;
```
Then go to ``Fun4All_HF.C`` and change cluster DST path to match with your input
```c++
  if (get_dEdx_info || get_detector_info)
  {
    std::string clus_file = "/sphenix/lustre01/sphnxpro/production/run2pp/physics/ana505_2024p023_v001/DST_TRKR_CLUSTER/run_"
                          + nice_rounded_down.str() + "_" + nice_rounded_up.str()
                          + "/dst/DST_TRKR_CLUSTER_run2pp_ana505_2024p023_v001-" + nice_runnumber.str() + "-" + nice_segment.str() + ".root";

    auto hitsinclus = new Fun4AllDstInputManager("ClusterInputManager");
    hitsinclus->fileopen(clus_file);
    se->registerInputManager(hitsinclus);
  }
```

- Submit jobs
Modify ``myCondor.job``, basically only change this line to your absolute local path
```
Initialdir         = ./
```
**Remember to create a ``log`` directory for condor output files (log,out,err).**
Use ``submitCondorJobs.sh`` to submit jobs. Modify this line to whatever runs you want to analyze, and separate the different runs with spaces.
```
runs="53783 53756 53877 53876"
```
Then exeute it
```
source submitCondorJobs.sh
```
QA outputs will show up in a new directory ``root/``

Have fun checking data! :)
